# Privacy Principles

_This document is part of a broader set of educational tools meant to drive shared understanding. It is designed for the groups assembling to go beyond the status quo to bring higher levels of accountability to the use of personal data in digital advertising._

## Purpose

A common understanding of these foundational principles, which represent user rights, will give way to stronger proposals and solutions from those who seek to deliver [accountability beyond the status quo](https://docs.google.com/a/iabtechlab.com/document/d/1WYC3taWPijdKTl_xHI9w8TxzgSLwnCBWtHuZkcLMw4w/edit?usp=drive_web). Additionally, this document demonstrates our intentions to the broader community. These intentions are based in the same foundations as those approaching digital privacy concerns through alternate methods (i.e. W3C, specific web browsers or identity solutions). We believe it is possible to share the same principles and arrive at a user-centered approach to personal data which creates much greater accountability _and_ a vibrant and competitive digital advertising industry. We feel the motivation to do both.

## Summary

While digital privacy concerns are making headlines today, ethics in personal data computing is not a new topic. Already in the 1960s academics explored conflicts in privacy and “surveillance” in light of emerging technologies.[^1] Shortly afterward, in the early 1970s, the Fair Information Practice Principles (FIPPs) were laid out by a U.S. Department of Health, Education and Welfare report[^2] and became the basis for the [Privacy Act of 1974](https://www.law.cornell.edu/uscode/text/5/552a). FIPPs now make up the basis for evolving privacy law—from the GDPR[^3] to CCPA[^4] and beyond—as well as private enterprises’ policies and existing standards like the Transparency and Consent Framework (TCF). This document explores those principles. It connects the dots between law and commercial policies to arrive at a super-set of privacy principles designed to guide understanding as we aim to increase accountability in digital advertising. These principles are only as good as consumers can trust that the companies processing their data will comply. This is why we seek thoughtful, demonstrable and air tight accountability standards for our ecosystem. 

### Principles

INSERT TOC

## Structure

This document is organized into:

1. Themes and their institutional roots (e.g. “Transparency”)
    1. Commercial approaches in appendices C - E
    2. Self-regulatory approaches in appendies
2. Practical applications of themes (e.g. “Company-level disclosure”)
3. Appendices to support the legitimacy of these principles

---

## Transparency

Based on FIPPs “openness principle,” “purpose specification principle” and “individual participation principle” plus “notice/awareness” in more recently written codes and [Recital 58](https://www.privacy-regulation.eu/en/recital-58-GDPR.htm) of the GDPR, transparency should remove shadows and suspicions surrounding personal data use in digital advertising. It should be easy to find and understand how and what personal data is collected and used for advertising. There should not be unknown parties to advertising transactions. The transparency principle is made up of the following high level activities:

### Company-level disclosure

Each company party to an advertising transaction should make itself and its personal data  processing practices known. 

### Access

Consumers should be able to see the personal data used for advertising which a company holds on them.

## Control

Based on several FIPPs principles including the “collection limitation principle,” “data quality principle,” “use limitation principle” and the “individual participation principle” as well as more recent developments like CCPA’s sale opt out and self-regulatory programs like NAI’s interest-based advertising opt out, consumers should have control over how their data can be used and shared. That control is embodied by:

### Choice

Transparency gives way to users being able to assert their preference with regard to data processing purposes or companies. That can take on several forms including opt-in and out-out.

### Deletion

Another form of control is the ability for a consumer to request that the data they see held on them through “access” is deleted by a company(ies) holding it.

### Correction

Similar to deletion, if a consumer sees inaccurate data held on them through “access” they should be able to request correction of the data.

## Use Limitation

Based on FIPPs “use limitation principle” and “security safeguards principle” plus the GDPR’s “purpose limitation principle” and CCPA’s service provider restrictions consumers should know that any personal data will not be used outside of the purpose(s) specified transparently by a company. Furthermore there are special types of data which must see an added demonstration of limitations, safeguards, security and integrity:

### Sensitive Category Data

There is currently no one list to rule them all with regard to commonly accepted sensitive categories. However, the digital advertising marketplace must recognize these do exist and demonstrate explicit transparency, control and restrictions over any personal data which may fall into this category.

### Precise Location Data

Several laws treat location data as a special category and thus subject to greater protections.[^5] 

## Data Minimization

Based in part on FIPPs “collection limitation principle” and recent reactions to the world of big data, data minimization is often thought of as redundantly with “use limitations.” However, even if a consumer’s preference allows for use of personal data for a certain purpose that company should not continue to collect data for that purpose beyond what is necessary and reasonable to fulfill the purpose.

## Data Portability

Data portability is a relatively new principle which is a result of advances in computing technology and personal data collection. Today several enterprises like Google and Facebook allow consumers to download their data and are further seeking to create open data portability standards. Recent laws like GDPR and CCPA have conferred portability rights for consumers.

---

## Appendix A

### Summary of rights afforded by the GDPR[^6]

**Section 1 Transparency and modalities**

*   Article 12 Transparent information, communication and modalities for the exercise of the rights of the data subject

**Section 2 Information and access to personal data**

*   Article 13 Information to be provided where personal data are collected from the data subject
*   Article 14 Information to be provided where personal data have not been obtained from the data subject
*   Article 15 Right of access by the data subject

**Section 3 Rectification and erasure**

*   Article 16 Right to rectification
*   Article 17 Right to erasure (‘right to be forgotten’)
*   Article 18 Right to restriction of processing
*   Article 19 Notification obligation regarding rectification or erasure of personal data or restriction of processing
*   Article 20 Right to data portability

**Section 4 Right to object and automated individual decision-making**

*   Article 21 Right to object
*   Article 22 Automated individual decision-making, including profiling

## Appendix B

### Summary of rights afforded by the CCPA[^7]

**Sections 1, 3 and 4 Rights to notice and access**

*   1798.100. (a) A consumer shall have the right to request that a business that collects a consumer’s personal information disclose to that consumer the categories and specific pieces of personal information the business has collected.
*   1798.110. (a) A consumer shall have the right to request that a business that collects personal information about the consumer disclose to the consumer the following ([see CCPA text](https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB1121))
*   1798.115. (a) A consumer shall have the right to request that a business that sells the consumer’s personal information, or that discloses it for a business purpose, disclose to that consumer ([see CCPA text](https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB1121))

**Section 2 Right to request deletion**

*   1798.105. (a) A consumer shall have the right to request that a business delete any personal information about the consumer which the business has collected from the consumer.

**Section 5 Right to opt out of sale**

*   1798.120. (a) A consumer shall have the right, at any time, to direct a business that sells personal information about the consumer to third parties not to sell the consumer’s personal information. This right may be referred to as the right to opt-out.

**Section 6 Right to equal services and prices**

*   1798.125. (a) (1) A business shall not discriminate against a consumer because the consumer exercised any of the consumer’s rights under this title, including, but not limited to, by ([see CCPA text](https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB1121))

## Appendix C

### Google’s Privacy & Security Principles[^8]

**Respect our users. Respect their privacy.**

We believe these ideas are inseparable. Together, they represent a single, core belief that has influenced everything we’ve made since day one, and everything we’ll make moving forward. When people use our products they trust us with their information, and it’s our job to do right by them. This means always being thoughtful about what data we use, how we use it, and how we protect it.

**Be clear about what data we collect and why.**

To help people make informed decisions about how they use Google products, we make it easy to understand what data we collect, how it’s used, and why. Being transparent means making this information readily available, understandable, and actionable.

**Never sell our users’ personal information to anyone.**

We use data to make Google products like Search and Maps as useful as possible. We also use data to serve more relevant ads. While these ads help fund our services and make them free for everyone, it’s important to clarify that our users’ personal information is simply not for sale.

**Make it easy for people to control their privacy.**

When it comes to privacy, we know one size doesn’t fit all. Every Google Account is built with on/off data controls, so our users can choose the privacy settings that are right for them. And as technology evolves, our privacy controls evolve as well, ensuring that privacy is always an individual choice that belongs to the user.

**Empower people to review, move, or delete their data.**

We believe every user should have access to the personal information they’ve shared with us – anytime and for any reason. That’s why we continue to make it easier for people to access and review their data, download and move it to another service if they want, or delete it entirely.

**Build the strongest security technologies into our products.**

Respecting the privacy of our users means protecting the data they trust us with. To keep every Google product and service secure for our users, we engineer and employ one of the most advanced security infrastructures in the world. This means constantly strengthening our built-in security technologies to detect and protect against evolving online threats, before they ever reach our users.

**Lead by example to advance online security for all.**

Keeping users safe online doesn’t stop with Google – it extends to the whole Internet. Google was the first company to create many of the security standards we all use today, and we continue to innovate new security technologies that can be used by everyone. We share our security learnings, experiences, and tools with partners, organizations, and competitors around the world, because Internet-wide security demands industry-wide collaboration.

## Appendix D

### Microsoft’s Privacy Principles[^9]

**Control**

We will put you in control of your privacy with easy-to-use tools and clear choices.

**Transparency**

We will be transparent about data collection and use so you can make informed decisions.

**Security**

We will protect the data you entrust to us through strong security and encryption.

**Strong legal protections**

We will respect your local privacy laws and fight for legal protection of your privacy as a fundamental human right.

**No content-based targeting**

We will not use your email, chat, files or other personal content to target ads to you.

**Benefits to you**

When we do collect data, we will use it to benefit you and to make your experiences better.

## Appendix E

### AT&T’s Privacy Approach[^10]

**Transparency**

We’re open and honest about how we use your data.

**Choice and Control**

We give you choices about how we use your data.

**Security**

We use strong safeguards to keep your data confidential and secure.

**Integrity**

We do what we say

<!-- Footnotes themselves at the bottom. -->
## Notes

[^1]:
     Privacy and Freedom, Alan Westin, 1967

[^2]:
     [Records, Computers and the Rights of Citizens](http://aspe.hhs.gov/datacncl/1973privacy/tocprefacemembers.htm)

[^3]:
     See Appendix A for a summary of rights afforded by the GDPR

[^4]:
     See Appendix B for a summary of rights afforded by the CCPA

[^5]:
     [https://fpf.org/2020/03/25/a-closer-look-at-location-data-privacy-and-pandemics/](https://fpf.org/2020/03/25/a-closer-look-at-location-data-privacy-and-pandemics/)

[^6]:
     [https://gdpr-info.eu/chapter-3/](https://gdpr-info.eu/chapter-3/)

[^7]:
     [https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB1121](https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB1121)

[^8]:
     [https://safety.google/principles/?hl=en_US](https://safety.google/principles/?hl=en_US)

[^9]:
     [https://privacy.microsoft.com/en-US/](https://privacy.microsoft.com/en-US/)

[^10]:
     [https://about.att.com/csr/home/privacy.html](https://about.att.com/csr/home/privacy.html)
